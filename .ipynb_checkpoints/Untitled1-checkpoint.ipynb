{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data of metric mem_used\n",
      "metric collected.\n",
      "Pre-processing Data...........\n",
      "{'__name__': 'mem_used', 'instance': '10.10.153.24:9100', 'job': 'server_24'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Duplicated timeseries in CollectorRegistry: {'predicted_mem_used_prophet'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4894591cb7ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[0mpredicted_metric_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"predicted_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m \u001b[0mPREDICTED_VALUES_PROPHET\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGauge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_metric_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_prophet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Forecasted value from Prophet model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcurrent_metric_metadata_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"__name__\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[0mPREDICTED_VALUES_PROPHET_UPPER\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGauge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_metric_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_prophet_yhat_upper'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Forecasted value upper bound from Prophet model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcurrent_metric_metadata_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"__name__\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[0mPREDICTED_VALUES_PROPHET_LOWER\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGauge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_metric_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_prophet_yhat_lower'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Forecasted value lower bound from Prophet model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcurrent_metric_metadata_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"__name__\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\prometheus_client\\metrics.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, documentation, labelnames, namespace, subsystem, unit, registry, labelvalues, multiprocess_mode)\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mregistry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregistry\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0mlabelvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabelvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m         )\n\u001b[0;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'multiprocess_mode'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_multiprocess_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\prometheus_client\\metrics.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, documentation, labelnames, namespace, subsystem, unit, registry, labelvalues)\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;31m# Register the multi-wrapper parent metric, or if a label-less metric, the whole shebang.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mlabelvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlabelkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\prometheus_client\\registry.py\u001b[0m in \u001b[0;36mregister\u001b[1;34m(self, collector)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 raise ValueError(\n\u001b[0;32m     28\u001b[0m                     'Duplicated timeseries in CollectorRegistry: {0}'.format(\n\u001b[1;32m---> 29\u001b[1;33m                         duplicates))\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_names_to_collectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Duplicated timeseries in CollectorRegistry: {'predicted_mem_used_prophet'}"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import prometheus\n",
    "import json\n",
    "import os\n",
    "import pandas\n",
    "from datetime import datetime, timedelta\n",
    "from sortedcontainers import SortedDict\n",
    "from fbprophet import Prophet\n",
    "from ast import literal_eval\n",
    "from prometheus_client import Gauge\n",
    "\n",
    "url = 'http://61.28.251.119:9090'\n",
    "metric_name = 'mem_used'\n",
    "print(\"Get data of metric {}\".format(metric_name))\n",
    "data_window = 1\n",
    "# Chunk size, download the complete data, but in smaller chunks, should be less than or equal to DATA_SIZE\n",
    "chunk_size = str(os.getenv('CHUNK_SIZE','2h'))\n",
    "\n",
    "# Net data size to scrape from prometheus\n",
    "data_size = str(os.getenv('DATA_SIZE','2h'))\n",
    "\n",
    "train_schedule = int(os.getenv('TRAINING_REPEAT_HOURS',6))\n",
    "\n",
    "TRUE_LIST = [\"True\", \"true\", \"1\", \"y\"]\n",
    "\n",
    "def get_df_from_json(metric, metric_dict_pd={}, data_window=5):\n",
    "    '''\n",
    "    Method to convert a json object of a Prometheus metric to a dictionary of shaped Pandas DataFrames\n",
    "\n",
    "    The shape is dict[metric_metadata] = Pandas Object\n",
    "\n",
    "    Pandas Object = timestamp, value\n",
    "                    15737933, 1\n",
    "                    .....\n",
    "\n",
    "    This method can also be used to update an existing dictionary with new data\n",
    "    '''\n",
    "    current_time = datetime.now()\n",
    "    earliest_data_time = current_time - timedelta(days = data_window)\n",
    "\n",
    "\n",
    "    print(\"Pre-processing Data...........\")\n",
    "    for row in metric:\n",
    "        # metric_dict[str(row['metric'])] = metric_dict.get(str(row['metric']),[]) + (row['values'])\n",
    "        metric_metadata = str(SortedDict(row['metric']))[11:-1] # Sort the dictionary and then convert it to string so it can be hashed\n",
    "        # print(metric_metadata)\n",
    "        # print(\"Row Values: \",row['values'])\n",
    "        if  metric_metadata not in metric_dict_pd:\n",
    "            metric_dict_pd[metric_metadata] = pandas.DataFrame(row['values'], columns=['ds', 'y']).apply(pandas.to_numeric, args=({\"errors\":\"coerce\"}))\n",
    "            metric_dict_pd[metric_metadata]['ds'] = pandas.to_datetime(metric_dict_pd[metric_metadata]['ds'], unit='s')\n",
    "            pass\n",
    "        else:\n",
    "            temp_df = pandas.DataFrame(row['values'], columns=['ds', 'y']).apply(pandas.to_numeric, args=({\"errors\":\"coerce\"}))\n",
    "            temp_df['ds'] = pandas.to_datetime(temp_df['ds'], unit='s')\n",
    "            metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].append(temp_df, ignore_index=True)\n",
    "            mask = (metric_dict_pd[metric_metadata]['ds'] > earliest_data_time)\n",
    "            metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].loc[mask]\n",
    "            pass\n",
    "        metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].dropna()\n",
    "        metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].drop_duplicates('ds').sort_values(by=['ds']).reset_index(drop = True)\n",
    "\n",
    "        if len(metric_dict_pd[metric_metadata]) == 0:\n",
    "            del metric_dict_pd[metric_metadata]\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "    return metric_dict_pd\n",
    "\n",
    "\n",
    "def predict_metrics(pd_dict, prediction_range=1):\n",
    "    '''\n",
    "    This Function takes input a dictionary of Pandas DataFrames, trains the Prophet model for each dataframe and returns a dictionary of predictions.\n",
    "    '''\n",
    "\n",
    "    total_label_num = len(pd_dict)\n",
    "    # LABEL_LIMIT = limit_labels\n",
    "    PREDICT_DURATION = prediction_range\n",
    "\n",
    "    current_label_num = 0\n",
    "    limit_iterator_num = 0\n",
    "\n",
    "    predictions_dict = {}\n",
    "\n",
    "    for meta_data in pd_dict:\n",
    "        try:\n",
    "            current_label_num += 1\n",
    "            limit_iterator_num += 1\n",
    "\n",
    "            print(\"Training Label {}/{}\".format(current_label_num,total_label_num))\n",
    "            data = pd_dict[meta_data]\n",
    "\n",
    "            print(\"----------------------------------\\n\")\n",
    "            print(meta_data)\n",
    "            print(\"Number of Data Points: {}\".format(len(pd_dict[meta_data])))\n",
    "            print(\"----------------------------------\\n\")\n",
    "\n",
    "            data['ds'] = pandas.to_datetime(data['ds'], unit='s')\n",
    "\n",
    "            train_frame = data\n",
    "\n",
    "            # Prophet Modelling begins here\n",
    "            m = Prophet(daily_seasonality = True, weekly_seasonality=True)\n",
    "\n",
    "            print(\"Fitting the train_frame\")\n",
    "            m.fit(train_frame)\n",
    "\n",
    "            future = m.make_future_dataframe(periods=int(PREDICT_DURATION),freq=\"1MIN\")\n",
    "\n",
    "            forecast = m.predict(future)\n",
    "\n",
    "            # To Plot\n",
    "            fig1 = m.plot(forecast)\n",
    "            #\n",
    "            fig2 = m.plot_components(forecast)\n",
    "            forecast['timestamp'] = forecast['ds']\n",
    "            forecast = forecast[['timestamp','yhat','yhat_lower','yhat_upper']]\n",
    "            forecast = forecast.set_index('timestamp')\n",
    "\n",
    "            # Store predictions in output dictionary\n",
    "            predictions_dict[meta_data] = forecast\n",
    "\n",
    "            # forecast.plot()\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "        except ValueError as exception:\n",
    "            if str(exception) == \"ValueError: Dataframe has less than 2 non-NaN rows.\":\n",
    "                print(\"Too many NaN values........Skipping this label\")\n",
    "                limit_iterator_num -= 1\n",
    "            else:\n",
    "                raise exception\n",
    "        pass\n",
    "\n",
    "    return predictions_dict\n",
    "\n",
    "def get_df_from_single_value_json(metric, metric_dict_pd={}, data_window=5):\n",
    "    '''\n",
    "    Method to convert a json object of a Prometheus metric to a dictionary of shaped Pandas DataFrames\n",
    "\n",
    "    The shape is dict[metric_metadata] = Pandas Object\n",
    "\n",
    "    Pandas Object = timestamp, value\n",
    "                    15737933, 1\n",
    "                    .....\n",
    "\n",
    "    This method can also be used to update an existing dictionary with new data\n",
    "    '''\n",
    "    # metric_dict = {}\n",
    "    current_time = datetime.now()\n",
    "    earliest_data_time = current_time - timedelta(days = data_window)\n",
    "\n",
    "\n",
    "    print(\"Pre-processing Data...........\")\n",
    "    # metric_dict_pd = {}\n",
    "    # print(\"Length of metric: \", len(metric))\n",
    "    for row in metric:\n",
    "        # metric_dict[str(row['metric'])] = metric_dict.get(str(row['metric']),[]) + (row['values'])\n",
    "        metric_metadata = str(SortedDict(row['metric']))[11:-1] # Sort the dictionary and then convert it to string so it can be hashed\n",
    "        # print(metric_metadata)\n",
    "        # print(\"Row Values: \",row['values'])\n",
    "        if  metric_metadata not in metric_dict_pd:\n",
    "            metric_dict_pd[metric_metadata] = pandas.DataFrame([row['value']], columns=['ds', 'y']).apply(pandas.to_numeric, args=({\"errors\":\"coerce\"}))\n",
    "            metric_dict_pd[metric_metadata]['ds'] = pandas.to_datetime(metric_dict_pd[metric_metadata]['ds'], unit='s')\n",
    "            pass\n",
    "        else:\n",
    "            temp_df = pandas.DataFrame([row['value']], columns=['ds', 'y']).apply(pandas.to_numeric, args=({\"errors\":\"coerce\"}))\n",
    "            temp_df['ds'] = pandas.to_datetime(temp_df['ds'], unit='s')\n",
    "            # print(temp_df.head())\n",
    "            # print(\"Row Values: \",row['values']\n",
    "            # print(\"Temp Head Before 5: \\n\",temp_df.head(5))\n",
    "            # print(\"Head Before 5: \\n\",metric_dict_pd[metric_metadata].head(5))\n",
    "            # print(\"Tail Before 5: \\n\",metric_dict_pd[metric_metadata].tail(5))\n",
    "            metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].append(temp_df, ignore_index=True)\n",
    "            # print(\"Head 5: \\n\",metric_dict_pd[metric_metadata].head(5))\n",
    "            # print(\"Tail 5: \\n\",metric_dict_pd[metric_metadata].tail(5))\n",
    "            mask = (metric_dict_pd[metric_metadata]['ds'] > earliest_data_time)\n",
    "            metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].loc[mask]\n",
    "            # del temp_df\n",
    "            pass\n",
    "        metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].dropna()\n",
    "        metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].drop_duplicates('ds').sort_values(by=['ds']).reset_index(drop = True)\n",
    "\n",
    "        if len(metric_dict_pd[metric_metadata]) == 0:\n",
    "            del metric_dict_pd[metric_metadata]\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "        # print(metric_dict_pd[metric_metadata])\n",
    "        # mask = (metric_dict_pd[metric_metadata]['ds'] > earliest_data_time) & (metric_dict_pd[metric_metadata]['ds'] <= current_time)\n",
    "        # metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].loc[mask]\n",
    "        # break\n",
    "    return metric_dict_pd\n",
    "\n",
    "def job(current_time):\n",
    "    global data_dict, predictions_dict_prophet, predictions_dict_fourier, current_metric_metadata, current_metric_metadata_dict, data_window, url, chunk_size, data_size, TRUE_LIST, store_intermediate_data\n",
    "    global data, config_list\n",
    "    prom = prometheus.Prometheus(url,chunk_size, data_size)\n",
    "    metric = prom.get_metric(metric_name)\n",
    "    print(\"metric collected.\")\n",
    "    metric = json.loads(metric)\n",
    "    data_dict = {}\n",
    "    data_dict = get_df_from_json(metric, data_dict, data_window)\n",
    "    #print(data_dict)\n",
    "    predictions_dict_prophet = {}\n",
    "    predictions_dict_fourier = {}\n",
    "    single_label_data_dict = {}\n",
    "    existing_config_list = list(data_dict.keys())\n",
    "    for existing_config in existing_config_list:\n",
    "        single_label_data_dict[existing_config] = data_dict[existing_config]\n",
    "\n",
    "                        \n",
    "    current_metric_metadata = list(single_label_data_dict.keys())[0]\n",
    "    current_metric_metadata_dict = literal_eval(current_metric_metadata)\n",
    "    print(current_metric_metadata)\n",
    "\n",
    "job(datetime.now())\n",
    "predicted_metric_name = \"predicted_\" + metric_name\n",
    "PREDICTED_VALUES_PROPHET = Gauge(predicted_metric_name + '_prophet', 'Forecasted value from Prophet model', [label for label in current_metric_metadata_dict if label != \"__name__\"])\n",
    "PREDICTED_VALUES_PROPHET_UPPER = Gauge(predicted_metric_name + '_prophet_yhat_upper', 'Forecasted value upper bound from Prophet model', [label for label in current_metric_metadata_dict if label != \"__name__\"])\n",
    "PREDICTED_VALUES_PROPHET_LOWER = Gauge(predicted_metric_name + '_prophet_yhat_lower', 'Forecasted value lower bound from Prophet model', [label for label in current_metric_metadata_dict if label != \"__name__\"])\n",
    "PREDICTED_ANOMALY_PROPHET = Gauge(predicted_metric_name + '_prophet_anomaly', 'Detected Anomaly using the Prophet model', [label for label in current_metric_metadata_dict if label != \"__name__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
