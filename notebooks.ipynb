{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "# Disable SSL warnings\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "DEBUG = False\n",
    "MAX_REQUEST_RETRIES = 5\n",
    "\n",
    "class Prometheus:\n",
    "    \"\"\"docstring for Prometheus.\"\"\"\n",
    "    def __init__(self, url='', end_time=None, data_chunk='1h',stored_data='1h'):\n",
    "        #self.headers = { 'Authorization': \"bearer {}\".format(token) }\n",
    "        self.url = url\n",
    "        self.prometheus_host = urlparse(self.url).netloc\n",
    "        self._all_metrics = None\n",
    "        self.data_chunk_size = data_chunk\n",
    "        self.end_time = datetime.datetime.now()\n",
    "        self.stored_data_range = stored_data\n",
    "        self.DATA_CHUNK_SIZE_LIST = {\n",
    "            '1m' : 60,\n",
    "            '3m' : 180,\n",
    "            '5m' : 300,\n",
    "            '30m': 1800,\n",
    "            '1h' : 3600,\n",
    "            '3h' : 10800,\n",
    "            '6h' : 21600,\n",
    "            '12h': 43200,\n",
    "            '1d' : 86400,\n",
    "            '2d' : 172800}\n",
    "\n",
    "    def all_metrics(self):\n",
    "        '''\n",
    "        Get the list of all the metrics that the prometheus host has\n",
    "        '''\n",
    "        if not self._all_metrics:\n",
    "            #response = requests.get('{0}/api/v1/label/__name__/values'.format(self.url),\n",
    "                                   # verify=False, # Disable ssl certificate verification temporarily\n",
    "                                   # headers=self.headers)\n",
    "            response = requests.get('{0}/api/v1/label/__name__/values'.format(self.url),\n",
    "                                    verify=False)\n",
    "            if DEBUG:\n",
    "               \n",
    "                print(\"URL => \", response.url)\n",
    "            if response.status_code == 200:\n",
    "                self._all_metrics = response.json()['data']\n",
    "            else:\n",
    "                raise Exception(\"HTTP Status Code {} {} ({})\".format(\n",
    "                    response.status_code,\n",
    "                    requests.status_codes._codes[response.status_code][0],\n",
    "                    response.content\n",
    "                ))\n",
    "            print(response)\n",
    "        return self._all_metrics\n",
    "\n",
    "    def get_metric(self, name, chunks=None, data_size=None):\n",
    "        if chunks:\n",
    "            if str(chunks) in self.DATA_CHUNK_SIZE_LIST:\n",
    "                self.data_chunk_size = str(chunks)\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Invalid Chunk Size, using default value: {}\".format(self.data_chunk_size))\n",
    "            pass\n",
    "        if data_size:\n",
    "            if str(data_size) in self.DATA_CHUNK_SIZE_LIST:\n",
    "                self.stored_data_range = str(data_size)\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Invalid Data Size, using default value: {}\".format(self.stored_data_range))\n",
    "            pass\n",
    "\n",
    "        if not name in self.all_metrics():\n",
    "            raise Exception(\"{} is not a valid metric\".format(name))\n",
    "        elif DEBUG:\n",
    "            print(\"Metric is valid.\")\n",
    "\n",
    "        # num_chunks = 1\n",
    "        num_chunks = int(self.DATA_CHUNK_SIZE_LIST[self.stored_data_range]/self.DATA_CHUNK_SIZE_LIST[self.data_chunk_size]) # Calculate the number of chunks using total data size and chunk size.\n",
    "        metrics = self.get_metrics_from_prom(name, num_chunks)\n",
    "        if metrics:\n",
    "            return metrics\n",
    "\n",
    "\n",
    "    def get_metrics_from_prom(self, name, chunks):\n",
    "        if not name in self.all_metrics():\n",
    "            raise Exception(\"{} is not a valid metric\".format(name))\n",
    "\n",
    "        # start = self.start_time.timestamp()\n",
    "        end_timestamp = self.end_time.timestamp()\n",
    "        chunk_size = self.DATA_CHUNK_SIZE_LIST[self.data_chunk_size]\n",
    "        start = end_timestamp - self.DATA_CHUNK_SIZE_LIST[self.stored_data_range] + chunk_size\n",
    "        data = []\n",
    "        for i in range(chunks):\n",
    "            # gc.collect() # Garbage collect to save Memory\n",
    "            if DEBUG:\n",
    "                print(\"Getting chunk: \", i)\n",
    "                print(\"Start Time: \",datetime.datetime.fromtimestamp(start))\n",
    "\n",
    "            tries = 0\n",
    "            while tries < MAX_REQUEST_RETRIES:  # Retry code in case of errors\n",
    "                response = requests.get('{0}/api/v1/query'.format(self.url),    # using the query API to get raw data\n",
    "                                        params={'query': name+'['+self.data_chunk_size+']',\n",
    "                                                'time': start\n",
    "                                                },\n",
    "                                        verify=False)\n",
    "                if DEBUG:\n",
    "                    print(response.url)\n",
    "                    pass\n",
    "\n",
    "                tries+=1\n",
    "                if response.status_code == 200:\n",
    "                    data += response.json()['data']['result']\n",
    "\n",
    "                    if DEBUG:\n",
    "                        # print(\"Size of recent chunk = \",getsizeof(data))\n",
    "                        # print(data)\n",
    "                        print(datetime.datetime.fromtimestamp(response.json()['data']['result'][0]['values'][0][0]))\n",
    "                        print(datetime.datetime.fromtimestamp(response.json()['data']['result'][0]['values'][-1][0]))\n",
    "                        pass\n",
    "\n",
    "                    del response\n",
    "                    tries = MAX_REQUEST_RETRIES\n",
    "                elif response.status_code == 504:\n",
    "                    if tries >= MAX_REQUEST_RETRIES:\n",
    "                        self.connection_errors_count+=1\n",
    "                        return False\n",
    "                    else:\n",
    "                        print(\"Retry Count: \",tries)\n",
    "                        sleep(CONNECTION_RETRY_WAIT_TIME)    # Wait for a second before making a new request\n",
    "                else:\n",
    "                    if tries >= MAX_REQUEST_RETRIES:\n",
    "                        self.connection_errors_count+=1\n",
    "                        raise Exception(\"HTTP Status Code {} {} ({})\".format(\n",
    "                            response.status_code,\n",
    "                            requests.status_codes._codes[response.status_code][0],\n",
    "                            response.content\n",
    "                        ))\n",
    "                    else:\n",
    "                        print(\"Retry Count: \",tries)\n",
    "                        sleep(CONNECTION_RETRY_WAIT_TIME)\n",
    "\n",
    "            start += chunk_size\n",
    "\n",
    "        return(json.dumps(data))\n",
    "\n",
    "    def get_current_metric_value(self, metric_name, label_config = None):\n",
    "        data = []\n",
    "        if label_config:\n",
    "            label_list = [str(key+\"=\"+ \"'\" + label_config[key]+ \"'\") for key in label_config]\n",
    "            # print(label_list)\n",
    "            query = metric_name + \"{\" + \",\".join(label_list) + \"}\"\n",
    "        else:\n",
    "            query = metric_name\n",
    "        response = requests.get('{0}/api/v1/query'.format(self.url),    # using the query API to get raw data\n",
    "                                params={'query': query},#label_config},\n",
    "                                verify=False, # Disable ssl certificate verification temporarily\n",
    "                                headers=self.headers)\n",
    "        data += response.json()['data']['result']\n",
    "        return (json.dumps(data))\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://61.28.251.119:9090\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metric value \n",
    "prom = Prometheus(url, '1h', '1h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "metric = prom.get_metric('mem_used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert metric to json \n",
    "metric = json.loads(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': {'__name__': 'mem_used',\n",
       "  'instance': '10.10.153.24:9100',\n",
       "  'job': 'server_24'},\n",
       " 'values': [[1554087904.361, '2.964752393756754'],\n",
       "  [1554087964.361, '2.9670497609739215'],\n",
       "  [1554088024.361, '2.9703959262684947'],\n",
       "  [1554088084.361, '2.9660009628965156'],\n",
       "  [1554088144.361, '2.9625549120707717'],\n",
       "  [1554088204.361, '30.523370217730488'],\n",
       "  [1554088264.361, '18.200741949725625'],\n",
       "  [1554088324.361, '2.9873265238037305'],\n",
       "  [1554088384.361, '2.969846555846999'],\n",
       "  [1554088444.361, '3.008652084710917'],\n",
       "  [1554088504.361, '2.978836253653313'],\n",
       "  [1554088564.361, '2.935186276527105'],\n",
       "  [1554088624.361, '2.9411794083979714'],\n",
       "  [1554088684.361, '2.9393814688367144'],\n",
       "  [1554088744.361, '2.933987650152929'],\n",
       "  [1554088804.361, '26.35819351023727'],\n",
       "  [1554088864.361, '53.3249396191964'],\n",
       "  [1554088924.361, '2.956062352543981'],\n",
       "  [1554088984.361, '2.94547448623878'],\n",
       "  [1554089044.361, '2.93458696334001'],\n",
       "  [1554089104.361, '2.926646063611102'],\n",
       "  [1554089164.361, '2.954763840638634'],\n",
       "  [1554089224.361, '2.9692971854255035'],\n",
       "  [1554089284.361, '2.9590089757138287'],\n",
       "  [1554089344.361, '2.955013554466575'],\n",
       "  [1554089404.361, '22.76026673432247'],\n",
       "  [1554089464.361, '12.25915101293917'],\n",
       "  [1554089524.361, '2.982532018307012'],\n",
       "  [1554089584.361, '2.977437856216781'],\n",
       "  [1554089644.361, '2.973841977094253'],\n",
       "  [1554089704.361, '2.969397070956674'],\n",
       "  [1554089764.361, '2.9670497609739215'],\n",
       "  [1554089824.361, '2.9748907751716587'],\n",
       "  [1554089884.361, '2.9590089757138287'],\n",
       "  [1554089944.361, '2.9545640695762643'],\n",
       "  [1554090004.361, '25.25825404086916'],\n",
       "  [1554090064.361, '34.508303484207104'],\n",
       "  [1554090124.361, '3.002559067308866'],\n",
       "  [1554090184.361, '3.004956320057218'],\n",
       "  [1554090244.361, '3.002908666668006'],\n",
       "  [1554090304.361, '3.0050062628228034'],\n",
       "  [1554090364.361, '3.0064046602593493'],\n",
       "  [1554090424.361, '3.0216372037644845'],\n",
       "  [1554090484.361, '3.012797334254941'],\n",
       "  [1554090544.361, '3.005705461541069'],\n",
       "  [1554090604.361, '25.235330311463073'],\n",
       "  [1554090664.361, '36.19232359715766'],\n",
       "  [1554090724.361, '3.037968488112625'],\n",
       "  [1554090784.361, '3.0287290764783563'],\n",
       "  [1554090844.361, '3.025133197355828'],\n",
       "  [1554090904.361, '3.020638348452678'],\n",
       "  [1554090964.361, '3.0162933278462845'],\n",
       "  [1554091024.361, '3.026082109902049'],\n",
       "  [1554091084.361, '3.0247336552311026'],\n",
       "  [1554091144.361, '3.013146933614081'],\n",
       "  [1554091204.361, '36.3610802020884'],\n",
       "  [1554091264.361, '51.691711298851516'],\n",
       "  [1554091324.361, '3.040415683626563'],\n",
       "  [1554091384.361, '3.0291286186030817'],\n",
       "  [1554091444.361, '3.017092412095735']]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pystan._api'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b3e5e9665df8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# convert json to data frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_df_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_window\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\code\\ml_anomaly_detector\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mceph\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCephConnect\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msortedcontainers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSortedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fbprophet\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# of patent rights can be found in the PATENTS file in the same directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecaster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'0.4'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fbprophet\\forecaster.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpystan\u001b[0m  \u001b[1;31m# noqa F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagnostics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprophet_copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pystan\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstanc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_rdump\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstan_rdump\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstansummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStanModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pystan\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m  \u001b[1;31m# stanc wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStanModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pystan._api'"
     ]
    }
   ],
   "source": [
    "# convert json to data frame\n",
    "import model\n",
    "data_dict = get_df_from_json(metric, data_dict, data_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
