{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "# Disable SSL warnings\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "DEBUG = False\n",
    "MAX_REQUEST_RETRIES = 5\n",
    "\n",
    "class Prometheus:\n",
    "    \"\"\"docstring for Prometheus.\"\"\"\n",
    "    def __init__(self, url='', end_time=None, data_chunk='1h',stored_data='1h'):\n",
    "        #self.headers = { 'Authorization': \"bearer {}\".format(token) }\n",
    "        self.url = url\n",
    "        self.prometheus_host = urlparse(self.url).netloc\n",
    "        self._all_metrics = None\n",
    "        self.data_chunk_size = data_chunk\n",
    "        self.end_time = datetime.datetime.now()\n",
    "        self.stored_data_range = stored_data\n",
    "        self.DATA_CHUNK_SIZE_LIST = {\n",
    "            '1m' : 60,\n",
    "            '3m' : 180,\n",
    "            '5m' : 300,\n",
    "            '30m': 1800,\n",
    "            '1h' : 3600,\n",
    "            '3h' : 10800,\n",
    "            '6h' : 21600,\n",
    "            '12h': 43200,\n",
    "            '1d' : 86400,\n",
    "            '2d' : 172800}\n",
    "\n",
    "    def all_metrics(self):\n",
    "        '''\n",
    "        Get the list of all the metrics that the prometheus host has\n",
    "        '''\n",
    "        if not self._all_metrics:\n",
    "            #response = requests.get('{0}/api/v1/label/__name__/values'.format(self.url),\n",
    "                                   # verify=False, # Disable ssl certificate verification temporarily\n",
    "                                   # headers=self.headers)\n",
    "            response = requests.get('{0}/api/v1/label/__name__/values'.format(self.url),\n",
    "                                    verify=False)\n",
    "            if DEBUG:\n",
    "               \n",
    "                print(\"URL => \", response.url)\n",
    "            if response.status_code == 200:\n",
    "                self._all_metrics = response.json()['data']\n",
    "            else:\n",
    "                raise Exception(\"HTTP Status Code {} {} ({})\".format(\n",
    "                    response.status_code,\n",
    "                    requests.status_codes._codes[response.status_code][0],\n",
    "                    response.content\n",
    "                ))\n",
    "            print(response)\n",
    "        return self._all_metrics\n",
    "\n",
    "    def get_metric(self, name, chunks=None, data_size=None):\n",
    "        if chunks:\n",
    "            if str(chunks) in self.DATA_CHUNK_SIZE_LIST:\n",
    "                self.data_chunk_size = str(chunks)\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Invalid Chunk Size, using default value: {}\".format(self.data_chunk_size))\n",
    "            pass\n",
    "        if data_size:\n",
    "            if str(data_size) in self.DATA_CHUNK_SIZE_LIST:\n",
    "                self.stored_data_range = str(data_size)\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Invalid Data Size, using default value: {}\".format(self.stored_data_range))\n",
    "            pass\n",
    "\n",
    "        if not name in self.all_metrics():\n",
    "            raise Exception(\"{} is not a valid metric\".format(name))\n",
    "        elif DEBUG:\n",
    "            print(\"Metric is valid.\")\n",
    "\n",
    "        # num_chunks = 1\n",
    "        num_chunks = int(self.DATA_CHUNK_SIZE_LIST[self.stored_data_range]/self.DATA_CHUNK_SIZE_LIST[self.data_chunk_size]) # Calculate the number of chunks using total data size and chunk size.\n",
    "        metrics = self.get_metrics_from_prom(name, num_chunks)\n",
    "        if metrics:\n",
    "            return metrics\n",
    "\n",
    "\n",
    "    def get_metrics_from_prom(self, name, chunks):\n",
    "        if not name in self.all_metrics():\n",
    "            raise Exception(\"{} is not a valid metric\".format(name))\n",
    "\n",
    "        # start = self.start_time.timestamp()\n",
    "        end_timestamp = self.end_time.timestamp()\n",
    "        chunk_size = self.DATA_CHUNK_SIZE_LIST[self.data_chunk_size]\n",
    "        start = end_timestamp - self.DATA_CHUNK_SIZE_LIST[self.stored_data_range] + chunk_size\n",
    "        data = []\n",
    "        for i in range(chunks):\n",
    "            # gc.collect() # Garbage collect to save Memory\n",
    "            if DEBUG:\n",
    "                print(\"Getting chunk: \", i)\n",
    "                print(\"Start Time: \",datetime.datetime.fromtimestamp(start))\n",
    "\n",
    "            tries = 0\n",
    "            while tries < MAX_REQUEST_RETRIES:  # Retry code in case of errors\n",
    "                response = requests.get('{0}/api/v1/query'.format(self.url),    # using the query API to get raw data\n",
    "                                        params={'query': name+'['+self.data_chunk_size+']',\n",
    "                                                'time': start\n",
    "                                                },\n",
    "                                        verify=False)\n",
    "                if DEBUG:\n",
    "                    print(response.url)\n",
    "                    pass\n",
    "\n",
    "                tries+=1\n",
    "                if response.status_code == 200:\n",
    "                    data += response.json()['data']['result']\n",
    "\n",
    "                    if DEBUG:\n",
    "                        # print(\"Size of recent chunk = \",getsizeof(data))\n",
    "                        # print(data)\n",
    "                        print(datetime.datetime.fromtimestamp(response.json()['data']['result'][0]['values'][0][0]))\n",
    "                        print(datetime.datetime.fromtimestamp(response.json()['data']['result'][0]['values'][-1][0]))\n",
    "                        pass\n",
    "\n",
    "                    del response\n",
    "                    tries = MAX_REQUEST_RETRIES\n",
    "                elif response.status_code == 504:\n",
    "                    if tries >= MAX_REQUEST_RETRIES:\n",
    "                        self.connection_errors_count+=1\n",
    "                        return False\n",
    "                    else:\n",
    "                        print(\"Retry Count: \",tries)\n",
    "                        sleep(CONNECTION_RETRY_WAIT_TIME)    # Wait for a second before making a new request\n",
    "                else:\n",
    "                    if tries >= MAX_REQUEST_RETRIES:\n",
    "                        self.connection_errors_count+=1\n",
    "                        raise Exception(\"HTTP Status Code {} {} ({})\".format(\n",
    "                            response.status_code,\n",
    "                            requests.status_codes._codes[response.status_code][0],\n",
    "                            response.content\n",
    "                        ))\n",
    "                    else:\n",
    "                        print(\"Retry Count: \",tries)\n",
    "                        sleep(CONNECTION_RETRY_WAIT_TIME)\n",
    "\n",
    "            start += chunk_size\n",
    "\n",
    "        return(json.dumps(data))\n",
    "\n",
    "    def get_current_metric_value(self, metric_name, label_config = None):\n",
    "        data = []\n",
    "        if label_config:\n",
    "            label_list = [str(key+\"=\"+ \"'\" + label_config[key]+ \"'\") for key in label_config]\n",
    "            # print(label_list)\n",
    "            query = metric_name + \"{\" + \",\".join(label_list) + \"}\"\n",
    "        else:\n",
    "            query = metric_name\n",
    "        response = requests.get('{0}/api/v1/query'.format(self.url),    # using the query API to get raw data\n",
    "                                params={'query': query},#label_config},\n",
    "                                verify=False, # Disable ssl certificate verification temporarily\n",
    "                                headers=self.headers)\n",
    "        data += response.json()['data']['result']\n",
    "        return (json.dumps(data))\n",
    "        pass\n",
    "def get_df_from_json(metric, metric_dict_pd={}, data_window=5):\n",
    "    '''\n",
    "    Method to convert a json object of a Prometheus metric to a dictionary of shaped Pandas DataFrames\n",
    "\n",
    "    The shape is dict[metric_metadata] = Pandas Object\n",
    "\n",
    "    Pandas Object = timestamp, value\n",
    "                    15737933, 1\n",
    "                    .....\n",
    "\n",
    "    This method can also be used to update an existing dictionary with new data\n",
    "    '''\n",
    "    current_time = datetime.now()\n",
    "    earliest_data_time = current_time - timedelta(days = data_window)\n",
    "\n",
    "\n",
    "    print(\"Pre-processing Data...........\")\n",
    "    for row in metric:\n",
    "        # metric_dict[str(row['metric'])] = metric_dict.get(str(row['metric']),[]) + (row['values'])\n",
    "        metric_metadata = str(SortedDict(row['metric']))[11:-1] # Sort the dictionary and then convert it to string so it can be hashed\n",
    "        # print(metric_metadata)\n",
    "        # print(\"Row Values: \",row['values'])\n",
    "        if  metric_metadata not in metric_dict_pd:\n",
    "            metric_dict_pd[metric_metadata] = pandas.DataFrame(row['values'], columns=['ds', 'y']).apply(pandas.to_numeric, args=({\"errors\":\"coerce\"}))\n",
    "            metric_dict_pd[metric_metadata]['ds'] = pandas.to_datetime(metric_dict_pd[metric_metadata]['ds'], unit='s')\n",
    "            pass\n",
    "        else:\n",
    "            temp_df = pandas.DataFrame(row['values'], columns=['ds', 'y']).apply(pandas.to_numeric, args=({\"errors\":\"coerce\"}))\n",
    "            temp_df['ds'] = pandas.to_datetime(temp_df['ds'], unit='s')\n",
    "            metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].append(temp_df, ignore_index=True)\n",
    "            mask = (metric_dict_pd[metric_metadata]['ds'] > earliest_data_time)\n",
    "            metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].loc[mask]\n",
    "            pass\n",
    "        metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].dropna()\n",
    "        metric_dict_pd[metric_metadata] = metric_dict_pd[metric_metadata].drop_duplicates('ds').sort_values(by=['ds']).reset_index(drop = True)\n",
    "\n",
    "        if len(metric_dict_pd[metric_metadata]) == 0:\n",
    "            del metric_dict_pd[metric_metadata]\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "    return metric_dict_pd\n",
    "\n",
    "\n",
    "def predict_metrics(pd_dict, prediction_range=1):\n",
    "    '''\n",
    "    This Function takes input a dictionary of Pandas DataFrames, trains the Prophet model for each dataframe and returns a dictionary of predictions.\n",
    "    '''\n",
    "\n",
    "    total_label_num = len(pd_dict)\n",
    "    # LABEL_LIMIT = limit_labels\n",
    "    PREDICT_DURATION = prediction_range\n",
    "\n",
    "    current_label_num = 0\n",
    "    limit_iterator_num = 0\n",
    "\n",
    "    predictions_dict = {}\n",
    "\n",
    "    for meta_data in pd_dict:\n",
    "        try:\n",
    "            current_label_num += 1\n",
    "            limit_iterator_num += 1\n",
    "\n",
    "            print(\"Training Label {}/{}\".format(current_label_num,total_label_num))\n",
    "            data = pd_dict[meta_data]\n",
    "\n",
    "            print(\"----------------------------------\\n\")\n",
    "            print(meta_data)\n",
    "            print(\"Number of Data Points: {}\".format(len(pd_dict[meta_data])))\n",
    "            print(\"----------------------------------\\n\")\n",
    "\n",
    "            data['ds'] = pandas.to_datetime(data['ds'], unit='s')\n",
    "\n",
    "            train_frame = data\n",
    "\n",
    "            # Prophet Modelling begins here\n",
    "            m = Prophet(daily_seasonality = True, weekly_seasonality=True)\n",
    "\n",
    "            print(\"Fitting the train_frame\")\n",
    "            m.fit(train_frame)\n",
    "\n",
    "            future = m.make_future_dataframe(periods=int(PREDICT_DURATION))\n",
    "\n",
    "            forecast = m.predict(future)\n",
    "\n",
    "            # To Plot\n",
    "            fig1 = m.plot(forecast)\n",
    "            #\n",
    "            fig2 = m.plot_components(forecast)\n",
    "            forecast['timestamp'] = forecast['ds']\n",
    "            forecast = forecast[['timestamp','yhat','yhat_lower','yhat_upper']]\n",
    "            forecast = forecast.set_index('timestamp')\n",
    "\n",
    "            # Store predictions in output dictionary\n",
    "            predictions_dict[meta_data] = forecast\n",
    "\n",
    "            # forecast.plot()\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "        except ValueError as exception:\n",
    "            if str(exception) == \"ValueError: Dataframe has less than 2 non-NaN rows.\":\n",
    "                print(\"Too many NaN values........Skipping this label\")\n",
    "                limit_iterator_num -= 1\n",
    "            else:\n",
    "                raise exception\n",
    "        pass\n",
    "\n",
    "    return predictions_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://61.28.251.119:9090\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metric value \n",
    "prom = Prometheus(url, '1h', '1h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "metric = prom.get_metric('mem_used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert metric to json \n",
    "metric = json.loads(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metric[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_window' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-816c0b434716>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_df_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_window\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_window' is not defined"
     ]
    }
   ],
   "source": [
    "# convert json to data frame\n",
    "import model\n",
    "data_dict = {}\n",
    "data_dict = get_df_from_json(metric, data_dict, data_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
